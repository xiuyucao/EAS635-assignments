---
title: "EAS635.001 Homework 2"
date: "9/18/2024"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Homework 2 aims to assess your ability to (1) calculate various characteristics of a random variable and a multivariate dataset, (2) determine whether or not variables in a dataset follow a normal distribution, and (3) perform a PCA.**

**There are 4 questions total. Please be sure to submit your R code as well as the output in one of the following formats for full credit: .pdf, .html**

## QUESTION 1

**For Q1-Q4, load in and use the data from the `forestfires.csv` file. The dataset has been sourced from <https://archive.ics.uci.edu/dataset/162/forest+fires> , there are multiple sites with different coordinates(X & Y) in the dataset, which is recorded with multiple forest fire events and the corresponding weather conditions.**

```{r}
### LOAD IN CSV FILE ("forestfires.csv")

```

### PART A

**Produce and show (1) a variance-covariance matrix and (2) a correlation matrix for the `fires` dataset. Please exclude any rows with missing data(NA values) first and exclude any variables that are inappropriate for these matrices.** 

**Hints: (1 The step of removing rows with NA values is very important since many functions used in multivariate analysis don't accepct NA values as the input (2 there are 12 columns in total of the data, but not all of them are meaningful to be used as the input of following analysis, please check the data table as well as the source website and determine which variables you are going to use**

```{r}
### ENTER CODE FOR Q1 PART A HERE

```

**1) Which two variables in the `fires` dataset are most highly correlated? (use code to identify)**

**Extra Credit Opportunity: You could write your own function in R to help you calculate and return the most highly correlated variables, the basic structure of R function could be found in section 2.5 of Zelterman**

ANSWER:

**2) Which two variables have the greatest covariance (absolute value)? Which variable has the smallest variance? (use code to identify)**

ANSWER (FOR GREATEST COVARIANCE):

ANSWER (FOR SMALLEST VARIANCE):

### PART B

**Calculate the Euclidean distances between all possible pairs of samples gained at the sites whose id is 75 (should be 7 total samples) with AND without scaling the variables beforehand. Print the output of the 2 distance matrices.**

```{r}
### ENTER CODE FOR Q1 PART B HERE

```

**Then, produce two dendrograms, one for each distance matrix (scaled and unscaled). To do so you can use the `hclust()` function with the distance matrix as input, and then use `plot()` on the output (please refer to textbook Zelterman 2015 page 288). No need for axses labels but please add a title. You are also encouraged to use other functions. Just make sure you understand the function you are using.**


```{r}
### ENTER CODE FOR Q1 PART B HERE

```

**Use your results to answer the two questions below:**

**1) Why might scaling your variables be a necessary step to take before calculating the distances between samples?**

ANSWER: 

**2) Which two forestfires samples from id 75 (row #1 - #7) are the most similar? Which two are the most different? (use code to process the scaled distance matrix to get the result)**

```{r}
### ENTER CODE FOR Q1 PART B HERE

```

ANSWER (EUCLIDEAN - MOST SIMILAR):

ANSWER (EUCLIDEAN - MOST DIFFERENT):

### PART C

**Calculate the "Canberra" distances between all possible pairs of all samples (except for the samples that were filtered out in Part A) in the `fires` dataset. No need to print the output.Then produce and show a dendrogram based on the "Canberra" distances.**

```{r}
### ENTER CODE FOR Q1 PART C HERE

```

## QUESTION 2

### PART A

**Produce a density plot of `temp` in the `fires` dataset without null values. Then, superimpose a plot of the normal probability density function for a variable with the same mean and standard deviation as the `temp` variable. Make the density plot blue and the normal probability density function red to distinguish between them. Make sure to appropriately label the plot axes and add a legend. Lines should be shown, not discrete points. (To clarify: there should only be one plot produced, but two curves plotted.)**

```{r}
### ENTER CODE FOR Q2 PART A HERE

```

### PART B

**Produce TWO different plots (should be different types, normally we expect you to plot QQ plot and histogram, but other types of plots that could help address this situation are encouraged as well) to visually check for the normality of `temp` in the filtered `fires` dataset. Comment on whether or not the data for this variable is normally distributed and how you were able to determine this from the plots you produced.**

```{r}
### ENTER CODE FOR Q2 PART B HERE

```

COMMENT: 

### PART C

**An arguably better way to test whether or not a variable is normally distributed, as opposed to producing a plot, is to use the Shapiro-Wilk test (`shapiro.test()`). The input is a vector of data and the output is the test statistic *W* and an associated p-value. If the p-value is less than the chosen $\alpha$, usually $\alpha = 0.05$, we reject the null hypothesis of the test, which is that the data are normally distributed, and conclude that the data are not normally distributed. For more information on the `shapiro.test()` function and an example of how to use it, type `?shapiro.test` in the console.**

**Now, use the Shapiro-Wilk normality test to test whether or not `dryweight` is normally distributed. Print your W and p-values. Comment on your results: are the data normally distributed or not?**

```{r}
### ENTER CODE FOR Q2 PART C HERE

```

COMMENT: 

## QUESTION 3

### PART A

**Calculate and print the Mahalanobis distance for each row of the `fires` dataset.**

```{r}
### ENTER CODE FOR Q3 PART A HERE

```

### PART B

**Produce a plot to determine if the `fires` data come from a multivariate normal distribution.**

```{r}
### ENTER CODE FOR Q3 PART B HERE

```

### PART C

**Answer the two questions below:**

**1) If data in a multivariate dataset come from a multivariate normal distribution, what kind of distribution will the Mahalanobis distance values follow? How do you determine the degrees of freedom? (Note: your answers should be general, not specific to any dataset.)**

ANSWER: 

**2) Regarding the plot you made in Part B, do the data come from a multivariate normal distribution? Explain how you came to this conclusion. (i.e., What would you expect to see if data come from a multivariate normal distribution, and does your plot meet these expectations?)**

ANSWER: 

## QUESTION 4

### PART A

**Conduct TWO principal components analyses (using whichever package and function you choose) of the `fires` data: one where the calculation uses the covariance matrix and one where the correlation matrix is used.**

```{r}
### ENTER CODE FOR Q4 PART A HERE

```

### PART B

**Report the number of components you think you need to explain the data and how much variance would be explained by your decision. Justify your decision by both summary your PCA result and displaying a plot showing the cumulative proportion of variance explained by each component.**

**Do this for both PCAs you performed in Part A.**

```{r}
### ENTER CODE FOR Q4 PART B(Summaries of PCA results) HERE

```

```{r}
### ENTER CODE FOR Q4 PART B(plots of PCA results) HERE

```

NUMBER OF COMPONENTS (COVARIANCE MATRIX): 

VARIANCE EXPLAINED (COVARIANCE MATRIX):

NUMBER OF COMPONENTS (CORRELATION MATRIX): 

VARIANCE EXPLAINED (CORRELATION MATRIX):

**Based on your results, answer the question below:**

**Which PCA produces a result where fewer components explain more of the variation in the data? Why might this be the case?**

ANSWER:

### PART C

**Print the loadings and present a biplot of the first two components for the PCA created using the correlation matrix in Q4 Part A (should be like Figure 8.2 on textbook Zelterman 2015 page 213)). Which variable contributes most to each component (use code to identify)? Interpret your biplot**

```{r}
### ENTER CODE FOR Q4 PART C HERE

```

Contribute most to component 1: 

Contribute most to component 2: 

INTERPRETATION OF BIPLOT:

What's the axes for the scatter points: (left&bottom or right&top)

What's the meaning of the numbers on these axes:

What's the axes for the arrows: (left&bottom or right&top)

What's the meaning of the numbers on these axes:


### PART D

**Answer the question below:**

**What is the difference between loadings and scores in the context of PCA?**

ANSWER:


**Extra Credit Opportunity: According to what we have learned in class, the arrows in the biplot represent the loadings of the variables, but in the biplot you created, the arrows are not pointing to the loadings,all the arrows seem a bit shorter than they should be. Can you explain why this is the case?**

ANSWER:
